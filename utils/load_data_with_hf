# from datasets import get_dataset_split_names
# ------------------- find all splits, for no only train -------------------
# splits = get_dataset_split_names("allenai/dolma")
# print(splits)

# ------------------- load the dataset -------------------
# import os
# from datasets import load_dataset

# os.environ["DATA_DIR"] = "/home/eisape/projects/diversify_lm_output/dolma/data"
# dataset = load_dataset("allenai/dolma", split="train")

# -------------------- inspect the .json.gz in dolma/data -------------------
import os
import gzip
import json
import glob

def inspect_dolma_data(data_dir, lines_to_print=1):
    """
    Prints out the structure of the .json.gz files in the directory.
    
    Parameters:
      data_dir (str): Path to the directory containing .json.gz files.
      lines_to_print (int): Number of lines (records) to print per file.
    """
    # Get list of all .json.gz files in data_dir
    file_list = glob.glob(os.path.join(data_dir, "*.json.gz"))
    if not file_list:
        print(f"No .json.gz files found in {data_dir}")
        return
    for file_path in file_list[:2]:
        print(f"\nInspecting file: {file_path}")
        with gzip.open(file_path, "rt", encoding="utf-8") as f:
            for i, line in enumerate(f):
                # Parse the JSON line into a Python dict
                record = json.loads(line)
                print(f"  Record {i+1}: {record}")
                # Stop after printing the desired number of lines
                if i + 1 >= lines_to_print:
                    break

if __name__ == "__main__":
    data_dir = os.getenv("DATA_DIR", "/home/eisape/projects/diversify_lm_output/dolma/data")
    inspect_dolma_data(data_dir, lines_to_print=1)

